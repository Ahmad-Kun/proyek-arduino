# -*- coding: utf-8 -*-
"""Bismillah FIXX Kesekian Kalinya.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l1VVI45_OTZi-qXPLahFjDfrDq9VYTkl
"""

# Import library untuk menghubungkan Google Drive dengan Google Colab
from google.colab import drive

# Mount Google Drive pada Google Colab
drive.mount('/content/drive')

# Set path ke folder yang berisi file JSON
import os
try:
  os.chdir('/content/drive/MyDrive/Magang/Penelitian_AI')
except:
  os.chdir('/content/drive/MyDrive/Semester6/Magang/Penelitian_AI')

from google.oauth2 import service_account
from googleapiclient.discovery import build

# set kredensial untuk API access
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
SERVICE_ACCOUNT_FILE = 'key_GoogleSheetAPI.json'
creds = None
creds = service_account.Credentials.from_service_account_file(
    SERVICE_ACCOUNT_FILE, scopes=SCOPES)

SPREADSHEET_ID = '1UeT7sqIsS8Ni3yLz6fh5GOBNJveyCpF_XAtQMRWC1Mo'
RANGE_NAME1 = 'Sheet1!J2:J1001'
RANGE_NAME2 = 'Sheet1!K2:K1001'

# buat koneksi ke Google Sheets API
service = build('sheets', 'v4', credentials=creds)
result1 = service.spreadsheets().values().get(
    spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME1).execute()
values1 = result1.get('values', [])

result2 = service.spreadsheets().values().get(
    spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME2).execute()
values2 = result2.get('values', [])

data_suhu_indoor = [float(item[0]) for item in values1]
data_suhu_outdoor = [float(item[0]) for item in values2]
print(len(data_suhu_indoor))
print(len(data_suhu_outdoor))

import numpy as np

num_samples = 1000
room_temp = np.array(data_suhu_indoor)
outdoor_temp = np.array(data_suhu_outdoor)
ac_temp = np.full((num_samples,), 20)

# Normalize the data Z-Score
room_temp_norm = (room_temp - np.mean(room_temp)) / np.std(room_temp)
outdoor_temp_norm = (outdoor_temp - np.mean(outdoor_temp)) / np.std(outdoor_temp)

# Create the input data and output labels
X = np.column_stack((room_temp_norm, outdoor_temp_norm, ac_temp))
y = ac_temp.reshape(-1, 1)

# Split the data into training and testing sets
train_ratio = 0.8
train_size = int(train_ratio * num_samples)
X_train, y_train = X[:train_size], y[:train_size]
X_test, y_test = X[train_size:], y[train_size:]

import tensorflow as tf
# Define the model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(3,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)
])

# Compile the model
model.compile(loss='mse', optimizer='adam', metrics=['mae'])

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32,
                    validation_data=(X_test, y_test))

# Make predictions
y_pred = model.predict(X_test)

# Print the mean absolute error
mae = np.mean(np.abs(y_test - y_pred))
print('MAE:', mae)

# Normalize the input data for tomorrow's prediction
tomorow_temp_in = 25
tomorow_temp_out = 28
room_temp_tomorrow = (tomorow_temp_in - np.mean(room_temp)) / np.std(room_temp)
outdoor_temp_tomorrow = (tomorow_temp_out - np.mean(outdoor_temp)) / np.std(outdoor_temp)

# Create the input data for tomorrow's prediction
X_tomorrow = np.array([[room_temp_tomorrow, outdoor_temp_tomorrow, 0]])

# Normalize the output label
y_mean = np.mean(ac_temp)
y_std = np.std(ac_temp)
ac_tomorrow_mean_norm = model.predict(X_tomorrow)[0][0]
ac_tomorrow_norm = ac_tomorrow_mean_norm * y_std + y_mean

# Print the predicted AC temperature for tomorrow
print('Predicted AC temperature tomorrow:', ac_tomorrow_norm)